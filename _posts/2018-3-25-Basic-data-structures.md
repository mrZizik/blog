---
layout: post
title: Базовые структуры данных
disqus: true
category: Study
tags: [study, computer-science, algorithms, array, list, linked list, algorithmic-complexity]
---

Продолжаем тему CS. В этом посте разберем базовые структуры данных, такие как: массив, связанный список, стек и очередь.

## Массив

Массив - структура данных, в которой элементы хранятся в памяти друг за другом. Для того, чтобы они не перезаписали другую информацию в стеке, массив имеет постоянный размер, который указывается при инициализации. Благодаря этому мы можем легко получить доступ к любому элементу массива по индексу за константное время. Адрес ячейки с нужным элементов будет равен адресу начала массива + размеру типа элементов массива * на индекс. Это значит, что массив является структурой данных с произвольным доступом.

Немного примеров на Java и C++:

```Java
int a[] = {1,2,3,4,5}; // Эта строка и весь код создают одинаковый массив
int b[] = new int[5];
b[0] = 1;
b[1] = 2;
...
...
b[4] = 5;

b[5] = -1; // Вызовет ошибку выхода за пределы массива, т.к. размер массива 5,а мы просим 6-ой элемет
``` 

```C++
int a[5] = {1,2,3,4,5};

int b[] = {1,2,3,4,5};

int c[5];
c[0] = 1;
c[1] = 2;
...
...
c[4] = 5;
```

### Динамические массивы

Что же делать если вы не знаете при создании, сколько элементов вам придется хранить в массиве? Для такого случая можно использовать динамические массивы. Единственное отличие их от обычных массивов в том, что когда вы пытаетесь добавить элемент в массив, в котором нет места, создается новый массив с большим размером, в который копируется весь первоначальный массив и добавляется элемент. Естественно, это плачевно сказывается на скорости.

## Сложность действий над массивом

|                                               |  Массив   | Динамический массив |
|-----------------------------------------------|-----------|---------------------|
| Доступ к элементу по индексу                  | O(1)      | O(1)                |
| Поиск элемента                                | O(n)/Ω(1) | O(n)/Ω(1)           |
| Добавление элемента в конец массива           | O(1)      | O(n)/Ω(1)           |
| Добавление элемента в начало/середину массива | O(n)      | O(n)                |
| Удаление элемента                             | O(n)/Ω(1) | O(n)/Ω(1)           |

Про доступ по элементу и почему он такой быстрый мы говорили выше. 

Поиск элемента так же затрагивался в посте про сложность алгоритмов, но повторим.
Допустим  у нас есть массив [1,2,3,4,5]. Для поиска нам необходимо пройтись по массиву один элемент за другим, сравнивая их с искомым. В худшем случае мы будем искать элемент, которого в массиве нет и чтобы понять это, нам надо пройти все N элементов, где N - размер массива. Больше массив, дольше поиск. Конечно в лучшем случае, мы будем искать первый элемент (в нашем случае 1) и за констатное время получим результат.

Добавление элемента в конец занимает констатное время, если в массиве есть место. В случае с обычным массивом, у нас нет случая, когда массив заполнен. Из-за этого вставка в конец занимает O(1). В динамическом массиве, пока место есть вставка так же будет занимать O(1), однако как только место закончится нам придется пройти через весь оригинальный массив и по одному копировать элементы в новый массив, что займет линейное количество времени.

Вставка в начало или середину массива занимает больше времени, т.к. нам необходимо сначала подвинуть все элементы, которые идут в вставляемой ячейке и после нее, чтобы сделать место для нашего элемента. 

Удаление элемента требует так же линейное время, т.к. после удаления, нам необходимо сдвинуть элементы массива после удаленного на один шаг.


